{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "pd.set_option('display.float_format', lambda x: '%.1f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in data, Sept 7th to Dec 7th, respresenting the fall semester for NYC public schools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: http://web.mta.info/developers/turnstile.html\n",
    "def get_data(week_nums):\n",
    "    url = \"http://web.mta.info/developers/data/nyct/turnstile/turnstile_{}.txt\"\n",
    "    dfs = []\n",
    "    for week_num in week_nums:\n",
    "        file_url = url.format(week_num)\n",
    "        dfs.append(pd.read_csv(file_url))\n",
    "    return pd.concat(dfs)\n",
    "        \n",
    "# weeks: sept 7th to december 7th, 2019    \n",
    "week_nums = [190907, 190914, 190921, 190928, 191005, 191012, 191019,\n",
    "            191026, 191102, 191109, 191116, 191123, 191130, 191207]\n",
    "df_read = get_data(week_nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the DataFrame we're working with a copy of the read-in data, so if an incorrect manipulation is made, can be reset easily without having to read in data again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2882165, 11)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_read \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a DATETIME column, and replacing DATE and TIME columns' entries (currently, 'object' types) with 'datetime objects':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"DATETIME\"] = pd.to_datetime(df[\"DATE\"] + \" \" + df[\"TIME\"], format=\"%m/%d/%Y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"DATE\"] = pd.to_datetime(df[\"DATE\"], format=\"%m/%d/%Y\")\n",
    "df[\"TIME\"] = pd.to_datetime(df[\"TIME\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning up column name for EXIT column, which had many trailing spaces: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'EXITS                                                               ':\"EXITS\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding actual entries and exits for each row (typically, 4-hour time period) by finding difference between each entry/exit 'total count' value and the value that precedes it, for each turnstile. We are filtering by C/A, UNIT, and SCP, since those 3 descriptors together define a single turnstile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_entries = df.groupby([\"C/A\", \"UNIT\", \"SCP\"]).agg({\"ENTRIES\": \"diff\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_exits = df.groupby([\"C/A\", \"UNIT\", \"SCP\"]).agg({\"EXITS\": \"diff\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The above used pandas \"diff\" as aggregating function. From pandas documention for \"diff\": \"Calculates the difference of a DataFrame element compared with another element in the DataFrame (default is the element in the same column of the previous row).\" This is exactly what we wanted to do. We broke it up into each individual unit first, becuase we only want it to subtract from entry/exit data for its own turnstile. therefore, first values for each turnstile, with nothing to subtract from (no preceding value), return NaN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding new columns for actual entries and exits to the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"REAL_ENTRIES\"] = real_entries[\"ENTRIES\"]\n",
    "df[\"REAL_EXITS\"] = real_exits[\"EXITS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the new real traffic data: there are many values which appear that are erroneous -- some which are extremely large and not possibly representative of real entries or exits in a 4-hour period, and some which are negative. Both types are likely caused by turnstile errors or resets, and need to be removed. Examples of the most extemely erroneous data included below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2440547   2037956058.0\n",
       "2027192   1754729527.0\n",
       "1402753   1704548686.0\n",
       "2027234   1554189845.0\n",
       "1157898    730710276.0\n",
       "1157894    730710263.0\n",
       "1157896    730710262.0\n",
       "1157892    730710255.0\n",
       "1157890    730710208.0\n",
       "73163      718560745.0\n",
       "Name: REAL_ENTRIES, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"REAL_ENTRIES\"].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73163     1886405893.0\n",
       "1402753   1019395842.0\n",
       "2440547    902456873.0\n",
       "366070     568618937.0\n",
       "1408555    300790885.0\n",
       "1815960    267405278.0\n",
       "2027192    150359755.0\n",
       "2027234    133731198.0\n",
       "1744346    100844994.0\n",
       "1616439    100304985.0\n",
       "Name: REAL_EXITS, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"REAL_EXITS\"].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1068802   -2025847485.0\n",
       "792556    -2013355772.0\n",
       "1204647   -1186521378.0\n",
       "1068768   -1121336461.0\n",
       "386825     -991539584.0\n",
       "1157895    -730710262.0\n",
       "1157897    -730710254.0\n",
       "1157893    -730710240.0\n",
       "1157899    -730710220.0\n",
       "1157891    -730710088.0\n",
       "Name: REAL_ENTRIES, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"REAL_ENTRIES\"].sort_values().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1068768   -1907466468.0\n",
       "1204647    -885740374.0\n",
       "792556     -839005509.0\n",
       "1397682    -721823991.0\n",
       "436975     -701914974.0\n",
       "1068802    -622024878.0\n",
       "386825     -504187450.0\n",
       "2024480     -50412910.0\n",
       "742744      -50330882.0\n",
       "207269      -20876713.0\n",
       "Name: REAL_EXITS, dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"REAL_EXITS\"].sort_values().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, removing the negative and NaN values from the data, knowing that this will remove the entire row which contains the error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df[\"REAL_ENTRIES\"] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df[\"REAL_EXITS\"] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2843278, 15)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, this has removed about 80,000 data points, which constitues only 2.5% of the total data. We have decided it is appropriate to remove this amount of data, since it not only comprises a very small percentage, but also because including the data would be for more skewing to our results since the values are so incorrect than would simply removing them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to remove the very large values -- practically, we want to eliminate entry/exit data which is abnormal for its specific turnstile/station. Some values (2000, e.g.) may be very normal for certain stations (like Times Square), but may be highly irregular for another station. If we define a cutoff threshhold above some general number for all of the data, that would allow 2000 to stay; but if a turnstile's average 4-hour ridership is only 15 people, a value of 2000 should in fact be removed and indicates an error (or, at best, a one-time anomolous event which we don't need to base our average values on anyway). It is for this reason that an arbitrary cut off value should not be chosen for the entire dataset, but rather averages for each station should inform that stations individual cutoff value for an unrealistic/error entry to be removed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this first requires finding average 4-hour (single-row) ridership values for each station. We are grouping by both STATION and LINENAME because we discovered that multiple stations have the same name, but are in fact separate (though nearby) and service different lines. Therefore it is the combination of STATION and LINENAME which comprise a single station. We are also using median over mean as our determination of 'average' ridership, because median values will be less skewed by the presence of extremely large error numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_averages = df.groupby([\"STATION\", \"LINENAME\"])[[\"REAL_ENTRIES\", \"REAL_EXITS\"]].mean()\n",
    "station_std = df.groupby([\"STATION\", \"LINENAME\"])[[\"REAL_ENTRIES\", \"REAL_EXITS\"]].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_averages.reset_index(inplace=True)\n",
    "station_std.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_averages.rename(columns={\"REAL_ENTRIES\":\"AVERAGE_ENTRIES\"}, inplace=True)\n",
    "station_averages.rename(columns={\"REAL_EXITS\":\"AVERAGE_EXITS\"}, inplace=True)\n",
    "station_std.rename(columns={\"REAL_ENTRIES\":\"ENTRIES_STD\"}, inplace=True)\n",
    "station_std.rename(columns={\"REAL_EXITS\":\"EXITS_STD\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding columns for average values into main DataFrame: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(left=df, right=station_averages, left_on=[\"STATION\", \"LINENAME\"], right_on=[\"STATION\", \"LINENAME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(left=df, right=station_std, left_on=[\"STATION\", \"LINENAME\"], right_on=[\"STATION\", \"LINENAME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C/A</th>\n",
       "      <th>UNIT</th>\n",
       "      <th>SCP</th>\n",
       "      <th>STATION</th>\n",
       "      <th>LINENAME</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DESC</th>\n",
       "      <th>ENTRIES</th>\n",
       "      <th>EXITS</th>\n",
       "      <th>DATETIME</th>\n",
       "      <th>REAL_ENTRIES</th>\n",
       "      <th>REAL_EXITS</th>\n",
       "      <th>AVERAGE_ENTRIES</th>\n",
       "      <th>AVERAGE_EXITS</th>\n",
       "      <th>ENTRIES_STD</th>\n",
       "      <th>EXITS_STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>2020-07-03 04:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>7183258</td>\n",
       "      <td>2433149</td>\n",
       "      <td>2019-08-31 04:00:00</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>152.9</td>\n",
       "      <td>99.1</td>\n",
       "      <td>178.7</td>\n",
       "      <td>166.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>2020-07-03 08:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>7183278</td>\n",
       "      <td>2433176</td>\n",
       "      <td>2019-08-31 08:00:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>152.9</td>\n",
       "      <td>99.1</td>\n",
       "      <td>178.7</td>\n",
       "      <td>166.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>2020-07-03 12:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>7183393</td>\n",
       "      <td>2433262</td>\n",
       "      <td>2019-08-31 12:00:00</td>\n",
       "      <td>115.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>152.9</td>\n",
       "      <td>99.1</td>\n",
       "      <td>178.7</td>\n",
       "      <td>166.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>2020-07-03 16:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>7183572</td>\n",
       "      <td>2433312</td>\n",
       "      <td>2019-08-31 16:00:00</td>\n",
       "      <td>179.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>152.9</td>\n",
       "      <td>99.1</td>\n",
       "      <td>178.7</td>\n",
       "      <td>166.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2019-08-31</td>\n",
       "      <td>2020-07-03 20:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>7183842</td>\n",
       "      <td>2433348</td>\n",
       "      <td>2019-08-31 20:00:00</td>\n",
       "      <td>270.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>152.9</td>\n",
       "      <td>99.1</td>\n",
       "      <td>178.7</td>\n",
       "      <td>166.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    C/A  UNIT       SCP STATION LINENAME DIVISION       DATE  \\\n",
       "0  A002  R051  02-00-00   59 ST  NQR456W      BMT 2019-08-31   \n",
       "1  A002  R051  02-00-00   59 ST  NQR456W      BMT 2019-08-31   \n",
       "2  A002  R051  02-00-00   59 ST  NQR456W      BMT 2019-08-31   \n",
       "3  A002  R051  02-00-00   59 ST  NQR456W      BMT 2019-08-31   \n",
       "4  A002  R051  02-00-00   59 ST  NQR456W      BMT 2019-08-31   \n",
       "\n",
       "                 TIME     DESC  ENTRIES    EXITS            DATETIME  \\\n",
       "0 2020-07-03 04:00:00  REGULAR  7183258  2433149 2019-08-31 04:00:00   \n",
       "1 2020-07-03 08:00:00  REGULAR  7183278  2433176 2019-08-31 08:00:00   \n",
       "2 2020-07-03 12:00:00  REGULAR  7183393  2433262 2019-08-31 12:00:00   \n",
       "3 2020-07-03 16:00:00  REGULAR  7183572  2433312 2019-08-31 16:00:00   \n",
       "4 2020-07-03 20:00:00  REGULAR  7183842  2433348 2019-08-31 20:00:00   \n",
       "\n",
       "   REAL_ENTRIES  REAL_EXITS  AVERAGE_ENTRIES  AVERAGE_EXITS  ENTRIES_STD  \\\n",
       "0          16.0         7.0            152.9           99.1        178.7   \n",
       "1          20.0        27.0            152.9           99.1        178.7   \n",
       "2         115.0        86.0            152.9           99.1        178.7   \n",
       "3         179.0        50.0            152.9           99.1        178.7   \n",
       "4         270.0        36.0            152.9           99.1        178.7   \n",
       "\n",
       "   EXITS_STD  \n",
       "0      166.8  \n",
       "1      166.8  \n",
       "2      166.8  \n",
       "3      166.8  \n",
       "4      166.8  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using average values to filter out any single 4-hour entry with ridership greater than 3 standard deviations from the mean. This will remove error values and also even if it removes a real value, if there was a surge of 2 orders of magnitude it is probably a standalone event that doesn't help inform our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df[\"REAL_ENTRIES\"] < 3*df[\"ENTRIES_STD\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df[\"REAL_EXITS\"] < 3*df[\"EXITS_STD\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2515606, 18)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after the removal of these high positive values, we have lost only about 4% of the total data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in observing the highest entry values, they are of normal and expected magnitude: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367310    14832.0\n",
       "367267    10233.0\n",
       "1256340    5968.0\n",
       "1652732    5204.0\n",
       "833191     5137.0\n",
       "335157     4830.0\n",
       "833233     4426.0\n",
       "1257520    4399.0\n",
       "2221917    4308.0\n",
       "1652721    4270.0\n",
       "Name: REAL_ENTRIES, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"REAL_ENTRIES\"].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                            23405\n",
       "C/A                               C022\n",
       "UNIT                              R212\n",
       "SCP                           01-00-02\n",
       "STATION                          59 ST\n",
       "LINENAME                           NRW\n",
       "DIVISION                           BMT\n",
       "DATE               2019-09-28 00:00:00\n",
       "TIME               2020-07-03 00:00:00\n",
       "DESC                           REGULAR\n",
       "ENTRIES                         108080\n",
       "EXITS                            52175\n",
       "DATETIME           2019-09-28 00:00:00\n",
       "REAL_ENTRIES                   14832.0\n",
       "REAL_EXITS                      7693.0\n",
       "AVERAGE_ENTRIES                  149.0\n",
       "AVERAGE_EXITS                     93.0\n",
       "Name: 367310, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[367310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                            23362\n",
       "C/A                               C022\n",
       "UNIT                              R212\n",
       "SCP                           01-00-01\n",
       "STATION                          59 ST\n",
       "LINENAME                           NRW\n",
       "DIVISION                           BMT\n",
       "DATE               2019-09-28 00:00:00\n",
       "TIME               2020-07-03 00:00:00\n",
       "DESC                           REGULAR\n",
       "ENTRIES                          80173\n",
       "EXITS                            50558\n",
       "DATETIME           2019-09-28 00:00:00\n",
       "REAL_ENTRIES                   10233.0\n",
       "REAL_EXITS                      7636.0\n",
       "AVERAGE_ENTRIES                  149.0\n",
       "AVERAGE_EXITS                     93.0\n",
       "Name: 367267, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[367267]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1999665   15980.0\n",
       "367310     7693.0\n",
       "367267     7636.0\n",
       "833275     6624.0\n",
       "43561      5598.0\n",
       "1945522    5203.0\n",
       "334899     5184.0\n",
       "778290     5097.0\n",
       "778339     5064.0\n",
       "774996     5005.0\n",
       "Name: REAL_EXITS, dtype: float64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"REAL_EXITS\"].sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                           142271\n",
       "C/A                              R161A\n",
       "UNIT                              R452\n",
       "SCP                           01-06-04\n",
       "STATION                          72 ST\n",
       "LINENAME                           123\n",
       "DIVISION                           IRT\n",
       "DATE               2019-11-21 00:00:00\n",
       "TIME               2020-07-03 16:00:00\n",
       "DESC                           REGULAR\n",
       "ENTRIES                         113700\n",
       "EXITS                           253104\n",
       "DATETIME           2019-11-21 16:00:00\n",
       "REAL_ENTRIES                     320.0\n",
       "REAL_EXITS                     15980.0\n",
       "AVERAGE_ENTRIES                  205.0\n",
       "AVERAGE_EXITS                    198.0\n",
       "Name: 1999665, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1999665]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing the new data, there are only 3 values that seem to still be obviously erroneous"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
